<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jonas Kristoffer Lindeløv" />


<title>Spearman is (almost) a Pearson on ranks</title>

<script src="simulate_spearman_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="simulate_spearman_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="simulate_spearman_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="simulate_spearman_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="simulate_spearman_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="simulate_spearman_files/navigation-1.1/tabsets.js"></script>
<link href="simulate_spearman_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="simulate_spearman_files/highlightjs-9.12.0/highlight.js"></script>
<link href="simulate_spearman_files/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="simulate_spearman_files/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Spearman is (almost) a Pearson on ranks</h1>
<h4 class="author">Jonas Kristoffer Lindeløv</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#simple-example"><span class="toc-section-number">1</span> Simple example</a></li>
<li><a href="#simulate-for-different-n-and-r"><span class="toc-section-number">2</span> Simulate for different N and r</a><ul>
<li><a href="#inspect-correlation-coefficients"><span class="toc-section-number">2.0.1</span> Inspect correlation coefficients</a></li>
<li><a href="#inspet-p-values"><span class="toc-section-number">2.0.2</span> Inspet p-values</a></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">3</span> Conclusion</a></li>
</ul>
</div>

<!-- from https://stackoverflow.com/a/37839683/1297830 -->
<link rel="stylesheet" type="text/css" href="hideOutput.css">
<script src="hideOutput.js"></script>
<p>This document presents the close relationship between Spearman correlation and Pearson correlation. Namely, that Spearman correlation is just a Pearson correlation on <span class="math inline">\(rank\)</span>ed <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. It is an appendix to the post “<a href="https://rpubs.com/lindeloev/test_as_linear">Common statistical tests as linear models</a>”.</p>
<p><strong>TL;DR: Below, I argue that this approximation is good enough when the sample size is 12 or greater and virtually perfect when the sample size is 20 or greater.</strong></p>
<div id="simple-example" class="section level1">
<h1><span class="header-section-number">1</span> Simple example</h1>
<p>Here, I start by creating some mildly correlated data. Note that the distribution of the data does not matter since everything is ranked, so the results are identical for non-normal data.</p>
<pre class="r"><code>data = MASS::mvrnorm(50, mu=c(2, 2), Sigma=cbind(c(1, 0.4), c(0.4, 1)))
x = data[,1]
y = data[,2]
plot(rank(y) ~ rank(x))</code></pre>
<p><img src="simulate_spearman_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
Now let’s test it
<div class="fold s">
<pre class="r"><code># Three ways of running the same model
spearman = cor.test(x, y, method=&#39;spearman&#39;)
pearson = cor.test(rank(x), rank(y), method=&#39;pearson&#39;)  # On ranks
linear = summary(lm(rank(y) ~ rank(x)))  # Linear is identical to pearson; just showing.

# Present the results
print(&#39;coefficient rho is exactly identical:&#39;)
rbind(spearman=spearman$estimate, 
      ranked_pearson=pearson$estimate, 
      ranked_linear=linear$coefficients[2])

print(&#39;p is approximately identical:&#39;)
rbind(spearman=spearman$p.value, 
      ranked_pearson=pearson$p.value, 
      ranked_linear=linear$coefficients[8])</code></pre>
<pre><code>## [1] &quot;coefficient rho is exactly identical:&quot;
##                      rho
## spearman       0.2319808
## ranked_pearson 0.2319808
## ranked_linear  0.2319808
## [1] &quot;p is approximately identical:&quot;
##                     [,1]
## spearman       0.1049734
## ranked_pearson 0.1050043
## ranked_linear  0.1050043</code></pre>
</div>
<p>The correlation coefficients are exact. And the p-values are quite close! But maybe we were just lucky? Let’s put it to the test:</p>
</div>
<div id="simulate-for-different-n-and-r" class="section level1">
<h1><span class="header-section-number">2</span> Simulate for different N and r</h1>
<p>The code below does the following:</p>
<ol style="list-style-type: decimal">
<li>Generate some correlated data for all combinations of the correlation coefficient (<span class="math inline">\(r = 0, 0.5, 0.95\)</span>) and sample sizes 1 <span class="math inline">\(N = 6, 8, 10, ... 20, 30, 50, 80\)</span>.</li>
<li>Compute coefficients and p-values for Spearman correlation test and Pearson correlation on the ranked values, many times for each combination.</li>
<li>Calculate the number of errors.</li>
</ol>
<pre class="r"><code>library(tidyverse)

# Settings for data simulation
PERMUTATIONS = 1:200
Ns = c(seq(from=6, to=20, by=2), 30, 50, 80)  # Sample sizes to model
rs = c(0, 0.5, 0.95)  # Correlation coefficients to model

# Begin
D = expand.grid(set=PERMUTATIONS, r=rs, N=Ns) %&gt;%  # Combinations of N and r
  mutate(
    # Use the parameters to generate correlated data in each row
    data = map2(N, r, function(N, r) MASS::mvrnorm(N, mu=c(0, 4), Sigma=cbind(c(1, r), c(r, 1)))),
    
    # Tests
    pearson_raw = map(data, ~cor.test(rank(.x[, 1]), rank(.x[, 2]), method=&#39;pearson&#39;)),
    spearman_raw = map(data, ~cor.test(.x[, 1], .x[, 2], method = &#39;spearman&#39;)),
    
    # Tidy it up
    pearson = map(pearson_raw, broom::tidy),
    spearman = map(spearman_raw, broom::tidy),
  ) %&gt;%
  
  # Get estimates &quot;out&quot; of the tidied results.
  unnest(pearson, spearman, .sep=&#39;_&#39;) %&gt;%
  select(-data, -pearson_raw, -spearman_raw)
  
  # If you want to do a permutation-based Spearman to better handle ties and
  # overcome issues on how to compute p (computationally heavy).
  # Corresponds very closely to R&#39;s spearman p-values
  #mutate(p.perm = map(data, ~ coin::pvalue(coin::spearman_test(.x[,1] ~ .x[,2], distribution=&#39;approximate&#39;)))) %&gt;%
  #unnest(p.perm)

head(D)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["set"],"name":[1],"type":["int"],"align":["right"]},{"label":["r"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["N"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["pearson_estimate"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["pearson_statistic"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["pearson_p.value"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["pearson_parameter"],"name":[7],"type":["int"],"align":["right"]},{"label":["pearson_conf.low"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["pearson_conf.high"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["pearson_method"],"name":[10],"type":["chr"],"align":["left"]},{"label":["pearson_alternative"],"name":[11],"type":["chr"],"align":["left"]},{"label":["spearman_estimate"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["spearman_statistic"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["spearman_p.value"],"name":[14],"type":["dbl"],"align":["right"]},{"label":["spearman_method"],"name":[15],"type":["chr"],"align":["left"]},{"label":["spearman_alternative"],"name":[16],"type":["chr"],"align":["left"]}],"data":[{"1":"1","2":"0","3":"6","4":"-0.65714286","5":"-1.7436255","6":"0.1561749","7":"4","8":"-0.9578640","9":"0.3308813","10":"Pearson's product-moment correlation","11":"two.sided","12":"-0.65714286","13":"58","14":"0.1750000","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"1"},{"1":"2","2":"0","3":"6","4":"0.14285714","5":"0.2886751","6":"0.7871720","7":"4","8":"-0.7563990","9":"0.8552617","10":"Pearson's product-moment correlation","11":"two.sided","12":"0.14285714","13":"30","14":"0.8027778","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"2"},{"1":"3","2":"0","3":"6","4":"0.25714286","5":"0.5321812","6":"0.6227872","7":"4","8":"-0.7006312","9":"0.8841859","10":"Pearson's product-moment correlation","11":"two.sided","12":"0.25714286","13":"26","14":"0.6583333","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"3"},{"1":"4","2":"0","3":"6","4":"0.08571429","5":"0.1720618","6":"0.8717434","7":"4","8":"-0.7801136","9":"0.8389184","10":"Pearson's product-moment correlation","11":"two.sided","12":"0.08571429","13":"32","14":"0.9194444","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"4"},{"1":"5","2":"0","3":"6","4":"-0.42857143","5":"-0.9486833","6":"0.3965015","7":"4","8":"-0.9201081","9":"0.5872384","10":"Pearson's product-moment correlation","11":"two.sided","12":"-0.42857143","13":"50","14":"0.4194444","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"5"},{"1":"6","2":"0","3":"6","4":"0.20000000","5":"0.4082483","6":"0.7040000","7":"4","8":"-0.7300588","9":"0.8703008","10":"Pearson's product-moment correlation","11":"two.sided","12":"0.20000000","13":"28","14":"0.7138889","15":"Spearman's rank correlation rho","16":"two.sided","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div id="inspect-correlation-coefficients" class="section level3">
<h3><span class="header-section-number">2.0.1</span> Inspect correlation coefficients</h3>
<p>Just as we saw in the simple example above, correlation coefficients (<code>estimate</code> and <code>estimate1</code>) are identical per definition. We can see that by calculating the difference and see that it is always zero:</p>
<pre class="r"><code>summary(D$estimate - D$estimate1)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## </code></pre>
<p>Yup. The minimum difference is zero. The maximum is zero. All of them are identicalNo need to look further into that.</p>
</div>
<div id="inspet-p-values" class="section level3">
<h3><span class="header-section-number">2.0.2</span> Inspet p-values</h3>
<p>Before getting started on p-values, note that there are several ways of calculating them for Spearman correlations. This is the relevant section from the documentation of <code>cor.test</code>:</p>
<blockquote>
<p>For Spearman’s test, p-values are computed using algorithm AS 89 for n &lt; 1290 and exact = TRUE, otherwise via the asymptotic t approximation. Note that these are ‘exact’ for n &lt; 10, and use an Edgeworth series approximation for larger sample sizes (the cutoff has been changed from the original paper).</p>
</blockquote>
<p>You can get beyond all of that by doing permutation-based tests at the cost of computational power (see outcommented code above). However, there is almost virtually perfect correspondence, so I just rely on R’s more computationally efficient p-values.</p>
<p>Below, I plot the difference between Spearman-derived p-values and ranked-Pearson-derived p-values. I have chosen not to plot as a function or <code>r</code> in the name of simplicity because it makes no difference whatsoever, but feel free to try it out yourself.</p>
<div class="fold s">
<pre class="r"><code>library(patchwork)

# A straight-up comparison of the p-values
p_relative = ggplot(D, aes(x=spearman_p.value, y=pearson_p.value, color=N)) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  geom_hline(yintercept=0.05, lty=2) +
  
  labs(title=&#39;Absolute relation&#39;, x = &#39;Spearman p-value&#39;, y = &#39;Pearson p-value&#39;) + 
  #coord_cartesian(xlim=c(0, 0.10), ylim=c(0, 0.11)) + 
  theme_gray(13) + 
  guides(color=FALSE)

# Looking at the difference (error) between p-values
p_error_all = ggplot(D, aes(x=spearman_p.value, y=pearson_p.value-spearman_p.value, color=factor(N))) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  
  labs(title=&#39;Error&#39;, x=&#39;Spearman p-value&#39;, y=&#39;Difference&#39;) + 
  coord_cartesian(ylim=c(-0.02, 0.005)) + 
  theme_gray(13) + 
  guides(color=FALSE)

# Same, but zoomed in around p=0.05
p_error_zoom = ggplot(D, aes(x=spearman_p.value, y=pearson_p.value-spearman_p.value, color=factor(N))) + 
  geom_line() + 
  geom_vline(xintercept=0.05, lty=2) +
  
  labs(title=&#39;Error zoomed&#39;, x=&#39;Spearman p-value&#39;, y=&#39;Difference&#39;) + 
  coord_cartesian(ylim=c(-0.02, 0.005), xlim=c(0, 0.10)) + 
  theme_gray(13)

# Show it. Patchwork is your friend!
p_relative + p_error_all + p_error_zoom</code></pre>
<p><img src="simulate_spearman_files/figure-html/unnamed-chunk-3-1.png" width="960" /></p>
</div>
<p><em>Figure: The jagget lines in the leftmost two panels are due to R computing “exact” p-values for Spearman when N &lt; 10. For samples larger than N&gt;=10, an approximation is used which gives a smoother relationship.</em></p>
<p>It is clear that larger N gives a closer correspondence. For small p, the Pearson-derived p-values are lower than Spearman, i.e. more liberal. Importantly, when N=12, this effect is at most 0.5% in the “significance-region” which I deem acceptable enough for the present purposes. When N=20, the error is at most 0.2% for the whole curve and there is no difference when N=50 or N=100.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1><span class="header-section-number">3</span> Conclusion</h1>
<p>The correlation coefficients are identical.</p>
<p>The p-value is exact enough when N &gt; 10 and virtualy perfect when N &gt; 20. If you are doing correlation studies on sample sizes lower than this, you have larger inferential problems than those posed by the slight differences between Spearman and Pearson.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
